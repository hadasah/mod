SPECS = {
            "transformer_lm_gpt3_small": {
                'NUM_GPUS': 16,
                "NUM_MOD_GPUS": 2,
                "NUM_STEPS": 80000,
                "TRAIN_HOURS": 48,
                "MOD_FROM_STEPS": [24000, 56000, 80000],
                "SAVE_INTERVAL_UPDATES": 6000,
                "LR": 5e-4,
                "UF": 32
            },
            "transformer_lm_gpt3_medium": {
                "NUM_GPUS": 32,
                "NUM_MOD_GPUS": 4,
                "NUM_STEPS": 32000,
                "MOD_FROM_STEPS": [8000, 14000],
                "TRAIN_HOURS": 48,
                "SAVE_INTERVAL_UPDATES": 2000,
                "LR": 5e-4,
                "UF": 32
            },
            "transformer_lm_gpt3_large": {
                'NUM_GPUS': 64,
                "NUM_MOD_GPUS": 8,
                "NUM_STEPS": 24000,
                "TRAIN_HOURS": 48,
                "MOD_FROM_STEPS": [2000,10000,16000],
                "SAVE_INTERVAL_UPDATES": 2000,
                "LR": 5e-4,
                "UF": 32
            },
            "transformer_lm_gpt3_xl": {
                'NUM_GPUS': 128,
                "NUM_MOD_GPUS": 16,
                "NUM_STEPS": 12000,
                "TRAIN_HOURS": 48,
                "MOD_FROM_STEPS": [4000,8000,12000],
                "SAVE_INTERVAL_UPDATES": 2000,
                "LR": 5e-4,
                "UF": 32
            },
}
EVAL_FOLDERS = {
        "transformer_lm_gpt3_small": {
            "dense": "/checkpoint/suching/mod_baselines/MODEL=transformerlmgpt3small_NUMGPUS=16_EXPERIMENT=dense_NUMSTEPS=80000_UPDATEFREQ=32_LR=0.0005/",
            "demix": "/checkpoint/suching/mod_baselines/MODEL=transformerlmgpt3small_NUMGPUS=16_EXPERIMENT=demix_NUMSTEPS=80000_UPDATEFREQ=32_LR=0.0005/",
            "mod": "/checkpoint/margaretli/mod/_modular_transformer_lm_gpt3_small/modular_transformer_lm_gpt3_small_LR=0.0005/",
            "average": "/checkpoint/suching/mod/average_transformer_lm_gpt3_small/",
            #"mod": "/checkpoint/suching/mod/_modular_gpt3_small_80K/modular_gpt3_small_80K_LR=0.0005/",
            "dense_24_domains": "/checkpoint/suching/mod_publication/NUMGPUS=24_EXPERIMENT=dense_NUMSTEPS=54000_UPDATEFREQ=32_LR=0.0005/"
        },
        "transformer_lm_gpt3_medium": {
            "dense": "/checkpoint/suching/mod_baselines/MODEL=transformerlmgpt3medium_NUMGPUS=32_EXPERIMENT=dense_NUMSTEPS=32000_UPDATEFREQ=32_LR=0.0005/",
            "demix": "/checkpoint/suching/mod_baselines/MODEL=transformerlmgpt3medium_NUMGPUS=32_EXPERIMENT=demix_NUMSTEPS=32000_UPDATEFREQ=32_LR=0.0005/",
            "average": "/checkpoint/suching/mod/average_transformer_lm_gpt3_medium/",
            "mod": "/checkpoint/margaretli/mod/_modular_transformer_lm_gpt3_medium/modular_transformer_lm_gpt3_medium_LR=0.0005/"
        },
        "transformer_lm_gpt3_large": {
            "dense": "/checkpoint/suching/mod_baselines/MODEL=transformerlmgpt3large_NUMGPUS=64_EXPERIMENT=dense_NUMSTEPS=24000_UPDATEFREQ=32_LR=0.0005/",
            "demix": "/checkpoint/suching/mod_baselines/MODEL=transformerlmgpt3large_NUMGPUS=64_EXPERIMENT=demix_NUMSTEPS=24000_UPDATEFREQ=32_LR=0.0005/",
            "mod": "/checkpoint/suching/mod/_modular_transformer_lm_gpt3_large/modular_transformer_lm_gpt3_large_LR=0.0005/"
        },
        "transformer_lm_gpt3_xl": {
            "dense": "",
            "demix": "",
            "mod": "",
            "dense_32_domains": "/checkpoint/suching/mod_publication/NUMGPUS=128_EXPERIMENT=dense_NUMSTEPS=16000_UPDATEFREQ=32_LR=0.0005/",
        }
}

DOMAINS = {
    "default_8_domains": ["1b_demix_paper",
"cs_demix_paper",
"anonymized_realnews_demix_paper",
"anonymized_reviews_demix_paper",
"anonymized_openwebtext_demix_paper",
"med_demix_paper",
"reddit_demix_paper",
"legal_demix_paper"],
    "default_16_domains": [
"Psychology",
"Chemistry",
"Economics",
"Engineering",
"materials",
"Geology",
"Sociology",
"Business",
"1b_demix_paper",
"cs_demix_paper",
"anonymized_realnews_demix_paper",
"anonymized_reviews_demix_paper",
"anonymized_openwebtext_demix_paper",
"med_demix_paper",
"reddit_demix_paper",
"legal_demix_paper"],
"default_32_domains": [ "Business",
"Sociology",
"polisci",
"Geology",
"materials",
"Engineering",
"Economics",
"Chemistry",
"Psychology",
"Geography",
"C++",
"C",
"Java",
"Mathematics",
"Physics",
"env_sci",
"HTML",
"JavaScript",
"Biology",
"twitter",
"stackoverflow",
"wikipedia",
"c4",
"gutenberg",
"1b_demix_paper",
"cs_demix_paper",
"anonymized_realnews_demix_paper",
"anonymized_reviews_demix_paper",
"anonymized_openwebtext_demix_paper",
"med_demix_paper",
"reddit_demix_paper",
"legal_demix_paper"],
    "default_64_domains" : ["Sociology",
"polisci",
"Geology",
"materials",
"Engineering",
"Economics",
"Chemistry",
"Psychology",
"Geography",
"C++",
"C",
"Java",
"Mathematics",
"Physics",
"env_sci",
"HTML",
"JavaScript",
"Biology",
"twitter",
"stackoverflow",
"wikipedia",
"c4",
"gutenberg",
"1b_demix_paper",
"cs_demix_paper",
"anonymized_realnews_demix_paper",
"anonymized_reviews_demix_paper",
"anonymized_openwebtext_demix_paper",
"med_demix_paper",
"reddit_demix_paper",
"legal_demix_paper",
"qasper_demix_paper",
"legal_contracts_demix_paper",
"anonymized_yelp_reviews_redo_demix_paper",
"Philosophy",
"cord19",
"stackexchange",
"stackoverflow",
"History",
"Books",
"art",
"Python",
"C#",
"PHP",
"Markdown",
"code_contests",
"Movies_and_TV",
"Software",
"pcgaming",
"financialindependence",
"cscareerquestions",
"nba",
"nfl",
"politics",
"movies",
"news",
"ukpolitics",
"explainlikeimfive",
"dc_text_20200604",
"Luxury_Beauty",
"Electronics",
"india",
"GO",
"CSS",
"Business"]
}